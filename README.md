# STeCa

This repository contains the code for the paper "STeCa: Step-level Trajectory Calibration for LLM Agent Learning"

<p align="center">
<img src=assets/framework.png width=700/>
</p>

In this work, We propose **S**tep-Level **T**raj**e**ctory **Ca**libration (**STeCa**), a novel framework for improving LLM agents. 
Specifically, \model identifies suboptimal actions through a step-level reward comparison during explorations. It constructs calibrated trajectories using LLM-driven reflection, enabling agents to learn from improved decision-making processes. These calibrated trajectories, together with successful trajectory data, are utilized for reinforced training.

## Usage 

Coming soon...

## Released Data and Results

Please refer to dataset/ for the released data of ALFWorld and VirtualHome.

## ðŸ“– Citation

If you find this repo helpful, please cite out paper:

```

```

## Acknowledgments

This codebase is built from [ETO](https://github.com/Yifan-Song793/ETO) and [IPR](https://github.com/WeiminXiong/IPR).